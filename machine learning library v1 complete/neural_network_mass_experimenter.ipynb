{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine_learning_functions import *\n",
    "from itertools import product\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_linear(a, b, learning_rate, epochs, random_x_function):\n",
    "    a, b = float(a), float(b)\n",
    "    model = Model(\n",
    "        FFN = FFN(\n",
    "            neurons_per_layer_list=[1, 1],\n",
    "            activation_functions_list=[None,],\n",
    "            cost_function=MSE()\n",
    "        ),\n",
    "        data_set=create_1_input_1_output_XY_data(\n",
    "            function=lambda x: a*x+b,\n",
    "            num_data_items=10000,\n",
    "            random_x_function=random_x_function\n",
    "        )\n",
    "    )\n",
    "    mean_cost, variance_cost = model.train_and_evaluate(\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=50\n",
    "    )\n",
    "    print(f\"Experiment results were:   mean_cost={mean_cost:.4f}   with   variance={variance_cost:.4f}\")\n",
    "\n",
    "    model.print_FFN_parameters()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_generator_factory_linear(coefficients, epochs_set, learning_rate_set, x_intervals):\n",
    "    for (a, b), learning_rate, epochs, x_interval in product(coefficients, learning_rate_set, epochs_set, x_intervals):\n",
    "        parameters = {\n",
    "            \"coefficients\": (a, b),\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"epochs\": epochs,\n",
    "            \"x_interval\": x_interval,\n",
    "        }\n",
    "        def experiment():\n",
    "            experiment_linear(\n",
    "                a=a, b=b, \n",
    "                learning_rate=learning_rate, \n",
    "                epochs=epochs, \n",
    "                random_x_function=lambda: random.uniform(*x_interval)\n",
    "            )\n",
    "        yield experiment, parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 0 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=0.0352   with   variance=0.0011\n",
      "Parameters of network\n",
      "{'W1': array([[1.6817033]])}\n",
      "{'B1': array([4.96075779])}\n",
      "\n",
      "\n",
      "Experiment 1 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=0.0019   with   variance=0.0000\n",
      "Parameters of network\n",
      "{'W1': array([[1.9997823]])}\n",
      "{'B1': array([4.9561862])}\n",
      "\n",
      "\n",
      "Experiment 2 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-100, 100)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henry\\Documents\\compsci presentations\\machine learning library 1\\machine_learning_functions.py:331: RuntimeWarning: overflow encountered in scalar add\n",
      "  total_cost += cost\n",
      "c:\\Users\\Henry\\Documents\\compsci presentations\\machine learning library 1\\machine_learning_functions.py:154: RuntimeWarning: overflow encountered in matmul\n",
      "  dcdAp = dZdAp.T @ dcdZ\n",
      "c:\\Users\\Henry\\Documents\\compsci presentations\\machine learning library 1\\machine_learning_functions.py:342: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  loss_change = new_loss - old_loss\n",
      "c:\\Users\\Henry\\Documents\\compsci presentations\\machine learning library 1\\machine_learning_functions.py:338: RuntimeWarning: overflow encountered in add\n",
      "  total_param_cost_gradients[param_name] += param_gradients[param_name]\n",
      "c:\\Users\\Henry\\Documents\\compsci presentations\\machine learning library 1\\machine_learning_functions.py:338: RuntimeWarning: invalid value encountered in add\n",
      "  total_param_cost_gradients[param_name] += param_gradients[param_name]\n",
      "c:\\Users\\Henry\\Documents\\compsci presentations\\machine learning library 1\\machine_learning_functions.py:166: RuntimeWarning: invalid value encountered in add\n",
      "  self.weights += weights_change\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment results were:   mean_cost=nan   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[nan]])}\n",
      "{'B1': array([nan])}\n",
      "\n",
      "\n",
      "Experiment 3 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=11.7296   with   variance=64.0723\n",
      "Parameters of network\n",
      "{'W1': array([[-0.17097378]])}\n",
      "{'B1': array([1.88670581])}\n",
      "\n",
      "\n",
      "Experiment 4 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=9.7853   with   variance=0.0025\n",
      "Parameters of network\n",
      "{'W1': array([[1.99864053]])}\n",
      "{'B1': array([1.87294099])}\n",
      "\n",
      "\n",
      "Experiment 5 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=inf   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[-8.5908801e+173]])}\n",
      "{'B1': array([-4.16322796e+171])}\n",
      "\n",
      "\n",
      "Experiment 6 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henry\\Documents\\compsci presentations\\machine learning library 1\\machine_learning_functions.py:386: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  (sum(cost**2 for cost in costs) / self.num_test_data_items)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment results were:   mean_cost=23.8632   with   variance=121.6089\n",
      "Parameters of network\n",
      "{'W1': array([[0.10221544]])}\n",
      "{'B1': array([0.23100418])}\n",
      "\n",
      "\n",
      "Experiment 7 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=24.4965   with   variance=256.0182\n",
      "Parameters of network\n",
      "{'W1': array([[1.72456855]])}\n",
      "{'B1': array([0.22839594])}\n",
      "\n",
      "\n",
      "Experiment 8 with parameters:\n",
      "{'coefficients': (2, 5), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=22.8950   with   variance=5.6721\n",
      "Parameters of network\n",
      "{'W1': array([[1.99564155]])}\n",
      "{'B1': array([0.22477958])}\n",
      "\n",
      "\n",
      "Experiment 9 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=1.1095   with   variance=1.2109\n",
      "Parameters of network\n",
      "{'W1': array([[-8.03492778]])}\n",
      "{'B1': array([6.0774623])}\n",
      "\n",
      "\n",
      "Experiment 10 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=0.0031   with   variance=0.0000\n",
      "Parameters of network\n",
      "{'W1': array([[-10.00134805]])}\n",
      "{'B1': array([5.94613624])}\n",
      "\n",
      "\n",
      "Experiment 11 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=nan   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[nan]])}\n",
      "{'B1': array([nan])}\n",
      "\n",
      "\n",
      "Experiment 12 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=39.7464   with   variance=2056.6721\n",
      "Parameters of network\n",
      "{'W1': array([[-0.77150528]])}\n",
      "{'B1': array([2.21872708])}\n",
      "\n",
      "\n",
      "Experiment 13 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=14.5648   with   variance=1.2460\n",
      "Parameters of network\n",
      "{'W1': array([[-9.97491064]])}\n",
      "{'B1': array([2.19522714])}\n",
      "\n",
      "\n",
      "Experiment 14 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=inf   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[4.50737555e+182]])}\n",
      "{'B1': array([1.1925979e+180])}\n",
      "\n",
      "\n",
      "Experiment 15 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=60.8318   with   variance=4721.9788\n",
      "Parameters of network\n",
      "{'W1': array([[-0.1521804]])}\n",
      "{'B1': array([0.28347933])}\n",
      "\n",
      "\n",
      "Experiment 16 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=142.9000   with   variance=25595.4484\n",
      "Parameters of network\n",
      "{'W1': array([[-8.15957445]])}\n",
      "{'B1': array([0.31143899])}\n",
      "\n",
      "\n",
      "Experiment 17 with parameters:\n",
      "{'coefficients': (-10, 6), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=32.4335   with   variance=8.9673\n",
      "Parameters of network\n",
      "{'W1': array([[-10.00450011]])}\n",
      "{'B1': array([0.30065807])}\n",
      "\n",
      "\n",
      "Experiment 18 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=0.0314   with   variance=0.0009\n",
      "Parameters of network\n",
      "{'W1': array([[0.18281722]])}\n",
      "{'B1': array([-1.22188529])}\n",
      "\n",
      "\n",
      "Experiment 19 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=0.0001   with   variance=0.0000\n",
      "Parameters of network\n",
      "{'W1': array([[0.49963903]])}\n",
      "{'B1': array([-1.23901371])}\n",
      "\n",
      "\n",
      "Experiment 20 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=nan   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[nan]])}\n",
      "{'B1': array([nan])}\n",
      "\n",
      "\n",
      "Experiment 21 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=0.6125   with   variance=0.0060\n",
      "Parameters of network\n",
      "{'W1': array([[0.41043768]])}\n",
      "{'B1': array([-0.46880341])}\n",
      "\n",
      "\n",
      "Experiment 22 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=0.6134   with   variance=0.0016\n",
      "Parameters of network\n",
      "{'W1': array([[0.49561386]])}\n",
      "{'B1': array([-0.46843591])}\n",
      "\n",
      "\n",
      "Experiment 23 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=inf   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[-3.05391063e+174]])}\n",
      "{'B1': array([4.03498621e+171])}\n",
      "\n",
      "\n",
      "Experiment 24 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=1.7828   with   variance=1.6214\n",
      "Parameters of network\n",
      "{'W1': array([[-0.3894789]])}\n",
      "{'B1': array([-0.05692627])}\n",
      "\n",
      "\n",
      "Experiment 25 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=1.7186   with   variance=1.9000\n",
      "Parameters of network\n",
      "{'W1': array([[0.40588774]])}\n",
      "{'B1': array([-0.05603698])}\n",
      "\n",
      "\n",
      "Experiment 26 with parameters:\n",
      "{'coefficients': (0.5, -1.25), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=1.4232   with   variance=0.0835\n",
      "Parameters of network\n",
      "{'W1': array([[0.49792096]])}\n",
      "{'B1': array([-0.05849936])}\n",
      "\n",
      "\n",
      "Experiment 27 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=156.5284   with   variance=19287.5667\n",
      "Parameters of network\n",
      "{'W1': array([[78.5168776]])}\n",
      "{'B1': array([-49.4183176])}\n",
      "\n",
      "\n",
      "Experiment 28 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=0.2043   with   variance=0.0002\n",
      "Parameters of network\n",
      "{'W1': array([[100.00250263]])}\n",
      "{'B1': array([-49.54677951])}\n",
      "\n",
      "\n",
      "Experiment 29 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=nan   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[nan]])}\n",
      "{'B1': array([nan])}\n",
      "\n",
      "\n",
      "Experiment 30 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Henry\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\numeric.py:925: RuntimeWarning: overflow encountered in multiply\n",
      "  return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis, :], out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment results were:   mean_cost=3817.0253   with   variance=15244382.2093\n",
      "Parameters of network\n",
      "{'W1': array([[15.67840185]])}\n",
      "{'B1': array([-19.29299329])}\n",
      "\n",
      "\n",
      "Experiment 31 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=941.3190   with   variance=2764.3648\n",
      "Parameters of network\n",
      "{'W1': array([[100.14853094]])}\n",
      "{'B1': array([-19.29171494])}\n",
      "\n",
      "\n",
      "Experiment 32 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=inf   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[-3.00773978e+173]])}\n",
      "{'B1': array([-5.93624267e+170])}\n",
      "\n",
      "\n",
      "Experiment 33 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=5598.0319   with   variance=37723461.8875\n",
      "Parameters of network\n",
      "{'W1': array([[1.75803752]])}\n",
      "{'B1': array([-2.29473383])}\n",
      "\n",
      "\n",
      "Experiment 34 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=13694.0292   with   variance=199801631.4091\n",
      "Parameters of network\n",
      "{'W1': array([[81.63129184]])}\n",
      "{'B1': array([-3.36385749])}\n",
      "\n",
      "\n",
      "Experiment 35 with parameters:\n",
      "{'coefficients': (100, -50), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=2294.7677   with   variance=62197.0548\n",
      "Parameters of network\n",
      "{'W1': array([[100.04252054]])}\n",
      "{'B1': array([-1.98074934])}\n",
      "\n",
      "\n",
      "Experiment 36 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=0.0302   with   variance=0.0000\n",
      "Parameters of network\n",
      "{'W1': array([[0.04522949]])}\n",
      "{'B1': array([19.82663065])}\n",
      "\n",
      "\n",
      "Experiment 37 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=0.0306   with   variance=0.0000\n",
      "Parameters of network\n",
      "{'W1': array([[0.00884923]])}\n",
      "{'B1': array([19.82469479])}\n",
      "\n",
      "\n",
      "Experiment 38 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=nan   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[nan]])}\n",
      "{'B1': array([nan])}\n",
      "\n",
      "\n",
      "Experiment 39 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=155.7527   with   variance=6.7889\n",
      "Parameters of network\n",
      "{'W1': array([[-0.17351634]])}\n",
      "{'B1': array([7.51020242])}\n",
      "\n",
      "\n",
      "Experiment 40 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=156.0582   with   variance=25.5918\n",
      "Parameters of network\n",
      "{'W1': array([[-0.02425085]])}\n",
      "{'B1': array([7.51299645])}\n",
      "\n",
      "\n",
      "Experiment 41 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=inf   with   variance=nan\n",
      "Parameters of network\n",
      "{'W1': array([[4.2180068e+173]])}\n",
      "{'B1': array([-1.69946121e+171])}\n",
      "\n",
      "\n",
      "Experiment 42 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1)}\n",
      "Experiment results were:   mean_cost=364.1591   with   variance=0.5743\n",
      "Parameters of network\n",
      "{'W1': array([[-0.02449318]])}\n",
      "{'B1': array([0.91907346])}\n",
      "\n",
      "\n",
      "Experiment 43 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10)}\n",
      "Experiment results were:   mean_cost=363.8455   with   variance=182.2841\n",
      "Parameters of network\n",
      "{'W1': array([[-0.04866113]])}\n",
      "{'B1': array([0.91980239])}\n",
      "\n",
      "\n",
      "Experiment 44 with parameters:\n",
      "{'coefficients': (0.01, 20), 'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-100, 100)}\n",
      "Experiment results were:   mean_cost=368.5328   with   variance=3490.1530\n",
      "Parameters of network\n",
      "{'W1': array([[0.03745652]])}\n",
      "{'B1': array([0.91489632])}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiemnt_generator = experiment_generator_factory_linear(\n",
    "    coefficients=(\n",
    "        (2, 5),\n",
    "        (-10, 6),\n",
    "        (1/2, -5/4),\n",
    "        (100, -50),\n",
    "        (1/100, 20)\n",
    "    ),\n",
    "    epochs_set=(\n",
    "        # 1, 5, 10, 20,\n",
    "        5,\n",
    "    ),\n",
    "    learning_rate_set=(\n",
    "        # 10**-2, 10**-3, 10**-4, 10**-5\n",
    "        10**-2, 10**-3, 10**-4,\n",
    "    ),\n",
    "    x_intervals = (\n",
    "        (-1, 1),      \n",
    "        (-10, 10),\n",
    "        (-100, 100),\n",
    "    ),\n",
    ")\n",
    "\n",
    "for i, (experiment, parameters) in enumerate(experiemnt_generator):\n",
    "    print(f\"Experiment {i} with parameters:\")\n",
    "    print(parameters)\n",
    "    experiment()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_learn_FFN(learning_rate, epochs, random_x_function, neurons_per_layer_list, activation_functions_list, cost_function):\n",
    "    target_FFN = FFN(\n",
    "        neurons_per_layer_list=neurons_per_layer_list,\n",
    "        activation_functions_list=activation_functions_list,\n",
    "        cost_function=cost_function\n",
    "    )\n",
    "\n",
    "    data_set = create_a_inputs_b_outputs_XY_data(\n",
    "        a=neurons_per_layer_list[0], \n",
    "        b=neurons_per_layer_list[-1],\n",
    "        num_data_items=10_000,\n",
    "        random_x_function= random_x_function,\n",
    "        function= lambda X: target_FFN.foreward_propagate(X)[0]\n",
    "    )\n",
    "\n",
    "\n",
    "    model_to_train = FFN(\n",
    "        neurons_per_layer_list=neurons_per_layer_list,\n",
    "        activation_functions_list=activation_functions_list,\n",
    "        cost_function=cost_function\n",
    "    )\n",
    "\n",
    "    model = Model(\n",
    "        FFN=model_to_train,\n",
    "        data_set=data_set\n",
    "    )\n",
    "    mean_cost, variance_cost = model.train_and_evaluate(\n",
    "        learning_rate=learning_rate,\n",
    "        epochs=epochs,\n",
    "        batch_size=50\n",
    "    )\n",
    "    \n",
    "    print(f\"Experiment results were:   mean_cost={mean_cost:.4f}   with   variance={variance_cost:.4f}\")\n",
    "\n",
    "    # model.print_FFN_parameters()\n",
    "\n",
    "    return (model, target_FFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_generator_factory_FFN(\n",
    "        learning_rates, epochs_sets, x_intervals, neurons_and_activation_layer_lists, cost_functions\n",
    "):\n",
    "    for learning_rate, epochs, x_interval, (neurons_per_layer_list, activation_functions_list), cost_function in product(\n",
    "        learning_rates, epochs_sets, x_intervals, neurons_and_activation_layer_lists, cost_functions\n",
    "    ):\n",
    "        parameters = {\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"epochs\": epochs,\n",
    "            \"x_interval\": x_interval,\n",
    "            \"neurons_per_layer_list\": neurons_per_layer_list,\n",
    "            \"activation_functions_list\": [type(activation).__name__ for activation in activation_functions_list],\n",
    "            \"cost_function\": type(cost_function).__name__,\n",
    "        }\n",
    "        def experiment():\n",
    "            return experiment_learn_FFN(\n",
    "                learning_rate=learning_rate, \n",
    "                epochs=epochs,\n",
    "                random_x_function=lambda: random.uniform(*x_interval),\n",
    "                neurons_per_layer_list=neurons_per_layer_list, \n",
    "                activation_functions_list=activation_functions_list,\n",
    "                cost_function=cost_function\n",
    "            )\n",
    "        yield experiment, parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 0 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=16.8693   with   variance=187596.7802\n",
      "\n",
      "\n",
      "Experiment 1 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0006   with   variance=0.0000\n",
      "\n",
      "\n",
      "Experiment 2 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=12.7590   with   variance=215239.4861\n",
      "\n",
      "\n",
      "Experiment 3 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0000   with   variance=0.0000\n",
      "\n",
      "\n",
      "Experiment 4 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=23.0485   with   variance=123543.4549\n",
      "\n",
      "\n",
      "Experiment 5 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0036   with   variance=0.0000\n",
      "\n",
      "\n",
      "Experiment 6 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=25.8338   with   variance=1254434.8038\n",
      "\n",
      "\n",
      "Experiment 7 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0001   with   variance=0.0000\n",
      "\n",
      "\n",
      "Experiment 8 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0149   with   variance=0.1005\n",
      "\n",
      "\n",
      "Experiment 9 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=9.6623   with   variance=185433.1869\n",
      "\n",
      "\n",
      "Experiment 10 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=4.8795   with   variance=45993.5613\n",
      "\n",
      "\n",
      "Experiment 11 with parameters:\n",
      "{'learning_rate': 0.01, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0000   with   variance=0.0000\n",
      "\n",
      "\n",
      "Experiment 12 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=11.7910   with   variance=94303.3348\n",
      "\n",
      "\n",
      "Experiment 13 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0025   with   variance=0.0000\n",
      "\n",
      "\n",
      "Experiment 14 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=2.3918   with   variance=2530.7338\n",
      "\n",
      "\n",
      "Experiment 15 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0158   with   variance=0.0002\n",
      "\n",
      "\n",
      "Experiment 16 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=16.8886   with   variance=287375.8552\n",
      "\n",
      "\n",
      "Experiment 17 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0081   with   variance=0.0001\n",
      "\n",
      "\n",
      "Experiment 18 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=44.2547   with   variance=2979528.8002\n",
      "\n",
      "\n",
      "Experiment 19 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0227   with   variance=0.0004\n",
      "\n",
      "\n",
      "Experiment 20 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.1712   with   variance=10.7434\n",
      "\n",
      "\n",
      "Experiment 21 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0010   with   variance=0.0000\n",
      "\n",
      "\n",
      "Experiment 22 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0238   with   variance=0.3400\n",
      "\n",
      "\n",
      "Experiment 23 with parameters:\n",
      "{'learning_rate': 0.001, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0000   with   variance=0.0000\n",
      "\n",
      "\n",
      "Experiment 24 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=629.1967   with   variance=645757580.9934\n",
      "\n",
      "\n",
      "Experiment 25 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0070   with   variance=0.0004\n",
      "\n",
      "\n",
      "Experiment 26 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=2.9561   with   variance=7709.6511\n",
      "\n",
      "\n",
      "Experiment 27 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-1, 1), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.3453   with   variance=0.0975\n",
      "\n",
      "\n",
      "Experiment 28 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=1923.0567   with   variance=7213178602.0723\n",
      "\n",
      "\n",
      "Experiment 29 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=38.6414   with   variance=732606.6395\n",
      "\n",
      "\n",
      "Experiment 30 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=12.0487   with   variance=105966.0981\n",
      "\n",
      "\n",
      "Experiment 31 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (0, 1), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.1302   with   variance=0.0200\n",
      "\n",
      "\n",
      "Experiment 32 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [5, 5, 5, 5], 'activation_functions_list': ['Sigmoid', 'Sigmoid', 'NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.1028   with   variance=5.7408\n",
      "\n",
      "\n",
      "Experiment 33 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [1, 10, 1], 'activation_functions_list': ['RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.1649   with   variance=5.6640\n",
      "\n",
      "\n",
      "Experiment 34 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [10, 20, 20, 10], 'activation_functions_list': ['RELU', 'RELU', 'Sigmoid'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=1.0898   with   variance=2007.3656\n",
      "\n",
      "\n",
      "Experiment 35 with parameters:\n",
      "{'learning_rate': 0.0001, 'epochs': 5, 'x_interval': (-10, 10), 'neurons_per_layer_list': [1, 1], 'activation_functions_list': ['NoneType'], 'cost_function': 'MSE'}\n",
      "Experiment results were:   mean_cost=0.0000   with   variance=0.0000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiemnt_generator = experiment_generator_factory_FFN(\n",
    "    neurons_and_activation_layer_lists=(\n",
    "        (\n",
    "            [5, 5, 5, 5],\n",
    "            [Sigmoid(), Sigmoid(), None]\n",
    "        ),\n",
    "        (\n",
    "            [1, 10, 1],\n",
    "            [RELU(), Sigmoid()]\n",
    "        ),\n",
    "        (\n",
    "            [10, 20, 20, 10],\n",
    "            [RELU(), RELU(), Sigmoid()]\n",
    "        ),\n",
    "        (\n",
    "            [1, 1],\n",
    "            [None]\n",
    "        )\n",
    "    ),\n",
    "    cost_functions=(\n",
    "        MSE(),\n",
    "    ),\n",
    "    epochs_sets=(\n",
    "        # 5, 10, 20,\n",
    "        5,\n",
    "    ),\n",
    "    learning_rates=(\n",
    "        10**-i for i in range(2, 5)\n",
    "    ),\n",
    "    x_intervals = (\n",
    "        (-1, 1),      \n",
    "        (0, 1),\n",
    "        (-10, 10),\n",
    "    ),\n",
    ")\n",
    "\n",
    "trained_models = []\n",
    "traget_FFNs = []\n",
    "for i, (experiment, parameters) in enumerate(experiemnt_generator):\n",
    "    print(f\"Experiment {i} with parameters:\")\n",
    "    print(parameters)\n",
    "    trained_model, traget_FFN = experiment()\n",
    "    trained_models.append(trained_model)\n",
    "    traget_FFNs.append(traget_FFN)\n",
    "    # model[i].print_parameters()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6994899  0.4040818  0.2370441  0.77315645 0.84399654]\n",
      "[ 0.02420778 -0.11349925  0.00229938 -0.06468189  0.15571875]\n",
      "[-0.60059206  0.22659928 -1.07501149  1.07400259 -0.63878825]\n",
      "0.71889685798548\n"
     ]
    }
   ],
   "source": [
    "# check result of experiment that supposedly went well\n",
    "\n",
    "experiment_index = 4\n",
    "x_range = (0, 1)\n",
    "\n",
    "X = np.array([random.uniform(*x_range) for _ in range(5)])\n",
    "Y, _ = traget_FFNs[experiment_index].foreward_propagate(X)\n",
    "P, _ = trained_models[experiment_index].FFN.foreward_propagate(X)\n",
    "cost = MSE()(P, Y)\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "print(P)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(traget_FFNs[experiment_index].tranformation_layers[2].bias)\n",
    "print(traget_FFNs[experiment_index].tranformation_layers[2].bias)\n",
    "\n",
    "print(\n",
    "    traget_FFNs[experiment_index].tranformation_layers[2].bias - traget_FFNs[experiment_index].tranformation_layers[2].bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "      print(\n",
    "            traget_FFNs[experiment_index].tranformation_layers[i].weights\n",
    "            -\n",
    "            traget_FFNs[experiment_index].tranformation_layers[i].weights\n",
    "      )\n",
    "      print(\n",
    "            traget_FFNs[experiment_index].tranformation_layers[i].bias\n",
    "            -\n",
    "            traget_FFNs[experiment_index].tranformation_layers[i].bias\n",
    "      )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
